{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24f44a7c-a018-45a8-a8fd-a3c744db96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "825ce5a2-2245-47e7-a2e7-9a171fea9b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\adity\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download \n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38cceb96-5559-4a2a-9df7-2e8eef8f0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=\"Natural Language Processing (NLP) is an interesting subject to have in syllabus. Lets have some fun with it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f19275c-251c-4f99-bc89-7c1c90a7e5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens :  ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'an', 'interesting', 'subject', 'to', 'have', 'in', 'syllabus', '.', 'Lets', 'have', 'some', 'fun', 'with', 'it', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens=word_tokenize(doc)\n",
    "print('tokens : ',tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0215c931-1146-433e-a755-6cacc3cb2848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " POS TAGS : [('Natural', 'JJ'), ('Language', 'NNP'), ('Processing', 'NNP'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('an', 'DT'), ('interesting', 'JJ'), ('subject', 'NN'), ('to', 'TO'), ('have', 'VB'), ('in', 'IN'), ('syllabus', 'NN'), ('.', '.'), ('Lets', 'NNS'), ('have', 'VBP'), ('some', 'DT'), ('fun', 'NN'), ('with', 'IN'), ('it', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags=pos_tag(tokens)\n",
    "print('\\n POS TAGS :',pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd6a4259-76f7-4ddd-b8f8-7a38da0d2365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token without stopwords :  ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'interesting', 'subject', 'syllabus', '.', 'Lets', 'fun', '.']\n"
     ]
    }
   ],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "token_without_stopwords=[word for word in tokens if word.lower() not in stop_words]\n",
    "print('token without stopwords : ',token_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae8ac6b0-12d4-4b83-9e88-91c831fc7607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemmed Tokens :  ['natur', 'languag', 'process', '(', 'nlp', ')', 'interest', 'subject', 'syllabu', '.', 'let', 'fun', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in token_without_stopwords]\n",
    "print('stemmed Tokens : ',stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed42423f-fb72-46ff-be3d-3df5962d89ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Tokens :  ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'interesting', 'subject', 'syllabus', '.', 'Lets', 'fun', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in token_without_stopwords]\n",
    "print('Lemmatized Tokens : ',lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc72457d-4f9b-478e-98aa-d076062c1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    doc,\n",
    "    \"Worthy to learn NLP\",\n",
    "    \"Lovely to have it to be in my Syllabus\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1dc12ca-b5bc-46e8-bed3-1ebfca1ccc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Representation (Features Name) :  ['fun' 'interesting' 'language' 'learn' 'lets' 'lovely' 'natural' 'nlp'\n",
      " 'processing' 'subject' 'syllabus' 'worthy']\n",
      "TF-IDF Matrix :  [[0.35013871 0.35013871 0.35013871 0.         0.35013871 0.\n",
      "  0.35013871 0.26628951 0.35013871 0.35013871 0.26628951 0.        ]\n",
      " [0.         0.         0.         0.62276601 0.         0.\n",
      "  0.         0.4736296  0.         0.         0.         0.62276601]\n",
      " [0.         0.         0.         0.         0.         0.79596054\n",
      "  0.         0.         0.         0.         0.60534851 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',lowercase=True)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "print('TF-IDF Representation (Features Name) : ',tfidf_vectorizer.get_feature_names_out())\n",
    "print('TF-IDF Matrix : ',tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4523cfc-897a-4978-b92b-cfb79f97ad8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
